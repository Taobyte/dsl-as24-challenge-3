{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import pytest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeismicDataset(Dataset):\n",
    "\n",
    "    def __init__(self, signal_folder_path: str, noise_folder_path: str, randomized = False):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            signal_folder_path (str): Path to earthquake signal folder containing .npz files.\n",
    "            noise_folder_path (str): Path to noise folder containing .npz files.\n",
    "        \"\"\"\n",
    "\n",
    "        self.signal_folder_path = signal_folder_path\n",
    "        self.noise_folder_path = noise_folder_path\n",
    "        self.eq_signal_files = glob.glob(f'{signal_folder_path}/**/*.npz', recursive=True)\n",
    "        self.noise_files = glob.glob(f'{noise_folder_path}/**/*.npz', recursive=True)\n",
    "        self.randomized = randomized\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.eq_signal_files)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[th.Tensor, int, str]:\n",
    "\n",
    "        eq_path = self.eq_signal_files[idx]\n",
    "        eq = np.load(eq_path, allow_pickle=True)\n",
    "        eq_name = (os.path.splitext(os.path.basename(eq_path)))[0]\n",
    "\n",
    "        noise_idx = np.random.randint(0, len(self.noise_files))\n",
    "        noise_path = self.noise_files[noise_idx]\n",
    "        noise = np.load(noise_path, allow_pickle=True)\n",
    "        noise_name = (os.path.splitext(os.path.basename(noise_path)))[0]\n",
    "\n",
    "        eq_start = 0\n",
    "        noise_start = 0\n",
    "        if self.randomized:\n",
    "            eq_start = np.random.randint(low = 0, high = 6000)\n",
    "            noise_start = np.random.randint(low = 0, high = 12000)\n",
    "\n",
    "        Z_eq = eq['earthquake_waveform_Z'][eq_start:eq_start+6000]\n",
    "        N_eq = eq['earthquake_waveform_N'][eq_start:eq_start+6000]\n",
    "        E_eq = eq['earthquake_waveform_E'][eq_start:eq_start+6000]\n",
    "        event = np.stack([Z_eq, N_eq, E_eq], axis=0)\n",
    "        eq_tensor = th.from_numpy(event)\n",
    "\n",
    "        Z_noise = noise['noise_waveform_Z'][noise_start:noise_start+6000]\n",
    "        N_noise = noise['noise_waveform_N'][noise_start:noise_start+6000]\n",
    "        E_noise = noise['noise_waveform_E'][noise_start:noise_start+6000]\n",
    "        noise_stacked = np.stack([Z_noise, N_noise, E_noise], axis=0)\n",
    "        noise_tensor = th.from_numpy(noise_stacked)\n",
    "\n",
    "        # tensor_normalized = eq_tensor / eqtensor.abs().max()\n",
    "\n",
    "        p_wave_start = 6000 - eq_start\n",
    "        # , p_wave_start, eq_name, noise_name\n",
    "\n",
    "        print(eq_tensor.shape)\n",
    "        print(noise_tensor.shape)\n",
    "\n",
    "        noisy_eq = eq_tensor + noise_tensor\n",
    "\n",
    "        return noisy_eq, eq_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.3, pytest-8.3.3, pluggy-1.5.0 -- c:\\Users\\cleme\\miniconda3\\envs\\dsl\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\cleme\\ETH\\Master\\DataLab\\dsl-as24-challenge-3\n",
      "plugins: anyio-4.2.0, typeguard-4.3.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "t_e216c054b0144360a2e83cb3a6ddf972.py::test_dataset_length \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "t_e216c054b0144360a2e83cb3a6ddf972.py::test_output_shape \u001b[32mPASSED\u001b[0m\u001b[32m                              [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 2.39s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "def test_dataset_length():\n",
    "    signal_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/signal/train\"\n",
    "    noise_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/noise/train\"\n",
    "    dataset = SeismicDataset(signal_folder, noise_folder)\n",
    "    assert len(dataset) == 20230 \n",
    "\n",
    "def test_output_shape():\n",
    "    signal_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/signal/train\"\n",
    "    noise_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/noise/train\"\n",
    "    dataset = SeismicDataset(signal_folder, noise_folder)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    next_tensor, noise_tensor = next(iter(dataloader))\n",
    "    print(next_tensor.shape)\n",
    "    print(noise_tensor.shape)\n",
    "    assert next_tensor.shape == (1,3,6000)\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDenoiserDataset(Dataset):\n",
    "\n",
    "    def __init__(self, signal_folder_path: str, noise_folder_path: str, randomized = True):\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            signal_folder_path (str): Path to earthquake signal folder containing .npz files.\n",
    "            noise_folder_path (str): Path to noise folder containing .npz files.\n",
    "        \"\"\"\n",
    "\n",
    "        self.signal_folder_path = signal_folder_path\n",
    "        self.noise_folder_path = noise_folder_path\n",
    "        self.eq_signal_files = glob.glob(f'{signal_folder_path}/**/*.npz', recursive=True)\n",
    "        self.noise_files = glob.glob(f'{noise_folder_path}/**/*.npz', recursive=True)\n",
    "        self.signal_length = 3000\n",
    "\n",
    "        self.randomized = randomized\n",
    "\n",
    "        #scipy hyperparameters\n",
    "        self.fs = 100\n",
    "        self.nperseg = 30\n",
    "        self.nfft = 60\n",
    "\n",
    "        # sample hyperparameters\n",
    "        self.noise_mean = 2\n",
    "        self.noise_std = 1\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.eq_signal_files)\n",
    "\n",
    "    def __getitem__(self, idx) -> th.Tensor:\n",
    "\n",
    "        eq_path = self.eq_signal_files[idx]\n",
    "        eq = np.load(eq_path, allow_pickle=True)\n",
    "        eq_name = (os.path.splitext(os.path.basename(eq_path)))[0]\n",
    "\n",
    "        noise_to_small = True\n",
    "        while noise_to_small:\n",
    "            noise_idx = np.random.randint(0, len(self.noise_files))\n",
    "            noise_path = self.noise_files[noise_idx]\n",
    "            noise = np.load(noise_path, allow_pickle=True)\n",
    "            if len(noise['noise_waveform_Z']) >= self.signal_length:\n",
    "                noise_to_small = False\n",
    "        \n",
    "        noise_name = (os.path.splitext(os.path.basename(noise_path)))[0]\n",
    "\n",
    "        noise_seq_len = len(noise['noise_waveform_Z'])\n",
    "        assert noise_seq_len >= self.signal_length\n",
    "\n",
    "        eq_start = 0\n",
    "        noise_start = 0\n",
    "        if self.randomized:\n",
    "            eq_start = np.random.randint(low = 0, high = 6000)\n",
    "            noise_start = np.random.randint(low = 0, high = max(noise_seq_len - self.signal_length, 1))\n",
    "\n",
    "        Z_eq = eq['earthquake_waveform_Z'][eq_start:eq_start+self.signal_length]\n",
    "        N_eq = eq['earthquake_waveform_N'][eq_start:eq_start+self.signal_length]\n",
    "        E_eq = eq['earthquake_waveform_E'][eq_start:eq_start+self.signal_length]\n",
    "        eq_stacked = np.stack([Z_eq, N_eq, E_eq], axis=0)\n",
    "        eq_tensor = th.from_numpy(eq_stacked)\n",
    "\n",
    "        Z_noise = noise['noise_waveform_Z'][noise_start:noise_start+self.signal_length]\n",
    "        N_noise = noise['noise_waveform_N'][noise_start:noise_start+self.signal_length]\n",
    "        E_noise = noise['noise_waveform_E'][noise_start:noise_start+self.signal_length]\n",
    "        noise_stacked = np.stack([Z_noise, N_noise, E_noise], axis=0)\n",
    "        noise_tensor = th.from_numpy(noise_stacked)\n",
    "\n",
    "        # sample random channel\n",
    "        j = np.random.choice([0, 1, 2])\n",
    "\n",
    "        eq = eq_stacked[j]\n",
    "        noise = noise_stacked[j]\n",
    "\n",
    "        def compute_stft(signal: ndarray) -> ndarray:\n",
    "\n",
    "            f, t, transform = scipy.signal.stft(\n",
    "                signal,\n",
    "                fs=self.fs,\n",
    "                nperseg=self.nperseg,\n",
    "                nfft=self.nfft,\n",
    "                boundary='zeros',\n",
    "            )\n",
    "            \n",
    "            return transform\n",
    "        \n",
    "        stft_eq = compute_stft(eq)\n",
    "        stft_noise = compute_stft(noise)\n",
    "\n",
    "        assert not np.isinf(stft_eq).any() and not np.isnan(stft_eq).any(), \"stft_eq nan or inf\"\n",
    "        assert not np.isinf(stft_noise).any() and not np.isnan(stft_noise).any(), \"stft_noise nan or inf\"\n",
    "\n",
    "        if np.random.random() < 0.9:\n",
    "\n",
    "            stft_eq = stft_eq / np.std(stft_eq)\n",
    "            \n",
    "            if np.random.random() < 0.2:\n",
    "                stft_eq = np.fliplr(stft_eq)\n",
    "        \n",
    "\n",
    "        ratio = 0\n",
    "        while ratio <= 0:\n",
    "            ratio = self.noise_mean + np.random.randn() * self.noise_std\n",
    "        \n",
    "        noisy = stft_eq + ratio * stft_noise\n",
    "        noisy = np.stack([noisy.real, noisy.imag], axis=-1)\n",
    "\n",
    "        assert not np.isnan(noisy).any() and not np.isinf(noisy).any(),  \"noisy nan or inf\"\n",
    "\n",
    "        noisy = noisy / np.std(noisy)\n",
    "        tmp_mask = np.abs(stft_eq) / (np.abs(stft_eq) + np.abs(ratio * stft_noise) + 1e-4)\n",
    "        tmp_mask[tmp_mask >= 1] = 1\n",
    "        tmp_mask[tmp_mask <= 0] = 0\n",
    "        mask = np.zeros([tmp_mask.shape[0], tmp_mask.shape[1], 2])\n",
    "        mask[:, :, 0] = tmp_mask\n",
    "        mask[:, :, 1] = 1 - tmp_mask\n",
    "\n",
    "\n",
    "        p_wave_start = 6000 - eq_start\n",
    "        # , p_wave_start, eq_name, noise_name\n",
    "\n",
    "        return th.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.12.3, pytest-8.3.3, pluggy-1.5.0 -- c:\\Users\\cleme\\miniconda3\\envs\\dsl\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\cleme\\ETH\\Master\\DataLab\\dsl-as24-challenge-3\n",
      "plugins: anyio-4.2.0, typeguard-4.3.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "t_4cda14160a14447493dc032bf2a5759f.py::test_dataset_length \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 50%]\u001b[0m\n",
      "t_4cda14160a14447493dc032bf2a5759f.py::test_output_shape \u001b[31mFAILED\u001b[0m\u001b[31m                              [100%]\u001b[0m\n",
      "\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m________________________________________ test_output_shape ________________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_output_shape\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        signal_folder = \u001b[33m\"\u001b[39;49;00m\u001b[33mC:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/signal/train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        noise_folder = \u001b[33m\"\u001b[39;49;00m\u001b[33mC:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/noise/train\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        dataset = DeepDenoiserDataset(signal_folder, noise_folder)\u001b[90m\u001b[39;49;00m\n",
      "        dataloader = DataLoader(dataset, batch_size=\u001b[94m1\u001b[39;49;00m, shuffle=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       next_tensor = \u001b[96mnext\u001b[39;49;00m(\u001b[96miter\u001b[39;49;00m(dataloader))\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\cleme\\AppData\\Local\\Temp\\ipykernel_17004\\937797925.py\u001b[0m:15: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mc:\\Users\\cleme\\miniconda3\\envs\\dsl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:630: in __next__\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m._next_data()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\cleme\\miniconda3\\envs\\dsl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:673: in _next_data\n",
      "    \u001b[0mdata = \u001b[96mself\u001b[39;49;00m._dataset_fetcher.fetch(index)  \u001b[90m# may raise StopIteration\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mc:\\Users\\cleme\\miniconda3\\envs\\dsl\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:52: in fetch\n",
      "    \u001b[0mdata = [\u001b[96mself\u001b[39;49;00m.dataset[idx] \u001b[94mfor\u001b[39;49;00m idx \u001b[95min\u001b[39;49;00m possibly_batched_index]\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <__main__.DeepDenoiserDataset object at 0x000001E06122F860>, idx = 711\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92m__getitem__\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, idx) -> th.Tensor:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        eq_path = \u001b[96mself\u001b[39;49;00m.eq_signal_files[idx]\u001b[90m\u001b[39;49;00m\n",
      "        eq = np.load(eq_path, allow_pickle=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        eq_name = (os.path.splitext(os.path.basename(eq_path)))[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        noise_to_small = \u001b[94mTrue\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwhile\u001b[39;49;00m noise_to_small:\u001b[90m\u001b[39;49;00m\n",
      "            noise_idx = np.random.randint(\u001b[94m0\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m.noise_files))\u001b[90m\u001b[39;49;00m\n",
      "            noise_path = \u001b[96mself\u001b[39;49;00m.noise_files[noise_idx]\u001b[90m\u001b[39;49;00m\n",
      "            noise = np.load(noise_path, allow_pickle=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m \u001b[96mlen\u001b[39;49;00m(noise[\u001b[33m'\u001b[39;49;00m\u001b[33mnoise_waveform_Z\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]) >= \u001b[96mself\u001b[39;49;00m.signal_length:\u001b[90m\u001b[39;49;00m\n",
      "                noise_to_small = \u001b[94mFalse\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        noise_name = (os.path.splitext(os.path.basename(noise_path)))[\u001b[94m0\u001b[39;49;00m]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        noise_seq_len = \u001b[96mlen\u001b[39;49;00m(noise[\u001b[33m'\u001b[39;49;00m\u001b[33mnoise_waveform_Z\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m noise_seq_len >= \u001b[96mself\u001b[39;49;00m.signal_length\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        eq_start = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        noise_start = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.randomized:\u001b[90m\u001b[39;49;00m\n",
      "            eq_start = np.random.randint(low = \u001b[94m0\u001b[39;49;00m, high = \u001b[94m6000\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "            noise_start = np.random.randint(low = \u001b[94m0\u001b[39;49;00m, high = \u001b[96mmax\u001b[39;49;00m(noise_seq_len - \u001b[96mself\u001b[39;49;00m.signal_length, \u001b[94m1\u001b[39;49;00m))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        Z_eq = eq[\u001b[33m'\u001b[39;49;00m\u001b[33mearthquake_waveform_Z\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][eq_start:eq_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        N_eq = eq[\u001b[33m'\u001b[39;49;00m\u001b[33mearthquake_waveform_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][eq_start:eq_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        E_eq = eq[\u001b[33m'\u001b[39;49;00m\u001b[33mearthquake_waveform_E\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][eq_start:eq_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        eq_stacked = np.stack([Z_eq, N_eq, E_eq], axis=\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        eq_tensor = th.from_numpy(eq_stacked)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        Z_noise = noise[\u001b[33m'\u001b[39;49;00m\u001b[33mnoise_waveform_Z\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][noise_start:noise_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        N_noise = noise[\u001b[33m'\u001b[39;49;00m\u001b[33mnoise_waveform_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][noise_start:noise_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        E_noise = noise[\u001b[33m'\u001b[39;49;00m\u001b[33mnoise_waveform_E\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][noise_start:noise_start+\u001b[96mself\u001b[39;49;00m.signal_length]\u001b[90m\u001b[39;49;00m\n",
      "        noise_stacked = np.stack([Z_noise, N_noise, E_noise], axis=\u001b[94m0\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "        noise_tensor = th.from_numpy(noise_stacked)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# sample random channel\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        j = np.random.choice([\u001b[94m0\u001b[39;49;00m, \u001b[94m1\u001b[39;49;00m, \u001b[94m2\u001b[39;49;00m])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        eq = eq_stacked[j]\u001b[90m\u001b[39;49;00m\n",
      "        noise = noise_stacked[j]\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m \u001b[92mcompute_stft\u001b[39;49;00m(signal: ndarray) -> ndarray:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            f, t, transform = scipy.signal.stft(\u001b[90m\u001b[39;49;00m\n",
      "                signal,\u001b[90m\u001b[39;49;00m\n",
      "                fs=\u001b[96mself\u001b[39;49;00m.fs,\u001b[90m\u001b[39;49;00m\n",
      "                nperseg=\u001b[96mself\u001b[39;49;00m.nperseg,\u001b[90m\u001b[39;49;00m\n",
      "                nfft=\u001b[96mself\u001b[39;49;00m.nfft,\u001b[90m\u001b[39;49;00m\n",
      "                boundary=\u001b[33m'\u001b[39;49;00m\u001b[33mzeros\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m transform\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        stft_eq = compute_stft(eq)\u001b[90m\u001b[39;49;00m\n",
      "        stft_noise = compute_stft(noise)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isinf(stft_eq).any() \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isnan(stft_eq).any()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isinf(stft_noise).any() \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isnan(stft_noise).any()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m np.random.random() < \u001b[94m0.9\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            stft_eq = stft_eq / np.std(stft_eq)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m np.random.random() < \u001b[94m0.2\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                stft_eq = np.fliplr(stft_eq)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        ratio = \u001b[94m0\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mwhile\u001b[39;49;00m ratio <= \u001b[94m0\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            ratio = \u001b[96mself\u001b[39;49;00m.noise_mean + np.random.randn() * \u001b[96mself\u001b[39;49;00m.noise_std\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        noisy = stft_eq + ratio * stft_noise\u001b[90m\u001b[39;49;00m\n",
      "        noisy = np.stack([noisy.real, noisy.imag], axis=-\u001b[94m1\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94massert\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isnan(noisy).any() \u001b[95mand\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m np.isinf(noisy).any()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AssertionError: assert (not True)\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where True = <built-in method any of numpy.ndarray object at 0x000001E05F47D4D0>()\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +    where <built-in method any of numpy.ndarray object at 0x000001E05F47D4D0> = array([[[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       ...,\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]]]).any\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +      where array([[[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       ...,\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]],\\n\\n       [[ True,  True],\\n        [ True,  True],\\n        [ True,  True],\\n        ...,\\n        [ True,  True],\\n        [ True,  True],\\n        [ True,  True]]]) = <ufunc 'isnan'>(array([[[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]],\\n\\n       [[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]],\\n\\n       [[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]],\\n\\n       ...,\\n\\n       [[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]],\\n\\n       [[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]],\\n\\n       [[nan, nan],\\n        [nan, nan],\\n        [nan, nan],\\n        ...,\\n        [nan, nan],\\n        [nan, nan],\\n        [nan, nan]]]))\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +        where <ufunc 'isnan'> = np.isnan\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\cleme\\AppData\\Local\\Temp\\ipykernel_17004\\3692106376.py\u001b[0m:108: AssertionError\n",
      "\u001b[33m======================================== warnings summary =========================================\u001b[0m\n",
      "notebooks/t_4cda14160a14447493dc032bf2a5759f.py::test_output_shape\n",
      "  C:\\Users\\cleme\\AppData\\Local\\Temp\\ipykernel_17004\\3692106376.py:95: RuntimeWarning: invalid value encountered in divide\n",
      "    stft_eq = stft_eq / np.std(stft_eq)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_4cda14160a14447493dc032bf2a5759f.py::\u001b[1mtest_output_shape\u001b[0m - AssertionError: assert (not True)\n",
      "\u001b[31m============================= \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 2.55s\u001b[0m\u001b[31m ==============================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "def test_dataset_length():\n",
    "    signal_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/signal/train\"\n",
    "    noise_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/noise/train\"\n",
    "    dataset = DeepDenoiserDataset(signal_folder, noise_folder)\n",
    "    assert len(dataset) == 20230 \n",
    "\n",
    "def test_output_shape():\n",
    "    signal_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/signal/train\"\n",
    "    noise_folder = \"C:/Users/cleme/ETH/Master/DataLab/dsl-as24-challenge-3/data/noise/train\"\n",
    "    dataset = DeepDenoiserDataset(signal_folder, noise_folder)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    next_tensor = next(iter(dataloader))\n",
    "    assert next_tensor.shape == (1,31,201,2)\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
