2024-11-05 18:38:19.321996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-05 18:38:19.339832: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-05 18:38:19.345084: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-05 18:38:20.769076: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
tuner: false
training: true
test: false
plot:
  metrics: false
  visualization: false
  n_examples: 3
snrs:
- 0.1
- 0.3
- 0.5
- 0.7
- 1.0
- 1.2
- 1.5
- 1.8
- 2.0
- 2.5
- 3.5
size_testset: 500
model:
  model_name: CleanUNet
  snr_lower: 0.1
  snr_upper: 2.0
  signal_length: 6120
  stft_loss: true
  batch_size: 32
  lr: 0.0002
  epochs: 10
  seed: 123
  channels_input: 3
  channels_output: 3
  dropout: 0.0
  channels_H: 64
  max_H: 768
  encoder_n_layers: 8
  kernel_size: 5
  stride: 2
  tsfm_n_layers: 5
  tsfm_n_head: 8
  tsfm_d_model: 512
  tsfm_d_inner: 2048
user:
  data:
    signal_path: /cluster/scratch/ckeusch/data/signal/
    noise_path: /cluster/scratch/ckeusch/data/noise/
    csv_path: /cluster/scratch/ckeusch/dsl-as24-challenge-3/data/
  model_path: /cluster/scratch/ckeusch/dsl-as24-challenge-3/outputs/2024-11-05/12-28-46/checkpoints/model_at_epoch_4.keras
  metrics_model_path: /cluster/scratch/ckeusch/dsl-as24-challenge-3/outputs/2024-11-02/10-10-22/metrics_model.csv
  metrics_butterworth_path: /cluster/scratch/ckeusch/dsl-as24-challenge-3/outputs/2024-11-02/10-10-22/metrics_butterworth.csv
  wandb: false

[2024-11-05 18:38:26,737][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-11-05 18:38:26,739][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
2024-11-05 18:38:33.454538: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 20.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.
Error executing job with overrides: []
Traceback (most recent call last):
  File "/cluster/scratch/ckeusch/dsl-as24-challenge-3/src/main.py", line 50, in main
    model = train_model(cfg)
            ^^^^^^^^^^^^^^^^
  File "/cluster/scratch/ckeusch/dsl-as24-challenge-3/src/train.py", line 21, in train_model
    model = fit_clean_unet(cfg)
            ^^^^^^^^^^^^^^^^^^^
  File "/cluster/scratch/ckeusch/dsl-as24-challenge-3/src/models/CleanUNet/train.py", line 102, in fit_clean_unet
    model.fit(
  File "/cluster/home/ckeusch/miniconda3/envs/CDiffSD/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/cluster/home/ckeusch/miniconda3/envs/CDiffSD/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/cluster/home/ckeusch/miniconda3/envs/CDiffSD/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/ckeusch/miniconda3/envs/CDiffSD/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cluster/home/ckeusch/miniconda3/envs/CDiffSD/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/cluster/scratch/ckeusch/dsl-as24-challenge-3/src/models/CleanUNet/dataset.py", line 65, in __getitem__
    assert np.any(np.isnan(noisy_eq)) or np.any(np.isnan(eq_stacked))
AssertionError

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
